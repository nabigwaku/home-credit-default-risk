{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e582e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Home Credit Default Risk - Data Exploration\n",
    "# \n",
    "# ## üìä Overview\n",
    "# This notebook explores the Home Credit dataset to understand:\n",
    "# 1. Data structure and relationships\n",
    "# 2. Missing values and data quality\n",
    "# 3. Target variable distribution\n",
    "# 4. Feature distributions and relationships\n",
    "# \n",
    "# ## üéØ Target Variable\n",
    "# - **TARGET = 1**: Client with payment difficulties\n",
    "# - **TARGET = 0**: Client without payment difficulties\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üì¶ Setup and Imports\n",
    "\n",
    "# %%\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import project utilities\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import load_config, load_data, display_data_info, get_file_sizes\n",
    "\n",
    "# %%\n",
    "# Load configuration\n",
    "config = load_config()\n",
    "print(\"Configuration loaded successfully\")\n",
    "\n",
    "# Check file sizes\n",
    "file_sizes = get_file_sizes()\n",
    "print(\"\\nFile sizes in MB:\")\n",
    "for file, size in file_sizes.items():\n",
    "    print(f\"  {file}: {size:.2f} MB\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìÅ Load Main Data Files\n",
    "\n",
    "# %%\n",
    "# Load application_train data (10% sample for quick exploration)\n",
    "print(\"Loading application_train data (10% sample)...\")\n",
    "app_train = load_data(config['files']['application_train'], nrows=None)  # Remove nrows for full data\n",
    "print(f\"\\nTraining data shape: {app_train.shape}\")\n",
    "\n",
    "# %%\n",
    "# Display basic information\n",
    "display_data_info(app_train, \"Application Train\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üéØ Target Variable Analysis\n",
    "\n",
    "# %%\n",
    "# Check target distribution\n",
    "if 'TARGET' in app_train.columns:\n",
    "    target_dist = app_train['TARGET'].value_counts()\n",
    "    target_pct = app_train['TARGET'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"Target Distribution:\")\n",
    "    print(f\"0 (No Payment Difficulties): {target_dist[0]:,} ({target_pct[0]:.2f}%)\")\n",
    "    print(f\"1 (Payment Difficulties): {target_dist[1]:,} ({target_pct[1]:.2f}%)\")\n",
    "    \n",
    "    # Plot target distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    sns.countplot(x='TARGET', data=app_train, ax=axes[0])\n",
    "    axes[0].set_title('Target Variable Distribution (Count)')\n",
    "    axes[0].set_xlabel('Target (0=No Default, 1=Default)')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, count in enumerate(target_dist):\n",
    "        axes[0].text(i, count + 1000, f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Percentage plot\n",
    "    axes[1].pie(target_dist.values, labels=['No Default', 'Default'], \n",
    "                autopct='%1.1f%%', startangle=90, colors=['lightgreen', 'lightcoral'])\n",
    "    axes[1].set_title('Target Variable Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üîç Missing Values Analysis\n",
    "\n",
    "# %%\n",
    "# Calculate missing values percentage for all columns\n",
    "missing = app_train.isnull().sum()\n",
    "missing_percent = 100 * missing / len(app_train)\n",
    "missing_df = pd.DataFrame({\n",
    "    'missing_count': missing,\n",
    "    'missing_percent': missing_percent\n",
    "})\n",
    "\n",
    "# Sort by missing percentage\n",
    "missing_df = missing_df[missing_df['missing_count'] > 0].sort_values('missing_percent', ascending=False)\n",
    "\n",
    "print(f\"Columns with missing values: {len(missing_df)}\")\n",
    "print(f\"Total missing cells: {missing.sum():,}\")\n",
    "print(f\"Overall data missing: {100 * missing.sum() / (app_train.shape[0] * app_train.shape[1]):.2f}%\")\n",
    "\n",
    "# %%\n",
    "# Visualize top 20 columns with highest missing values\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_missing = missing_df.head(20)\n",
    "    \n",
    "    plt.barh(range(len(top_missing)), top_missing['missing_percent'])\n",
    "    plt.yticks(range(len(top_missing)), top_missing.index)\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.title('Top 20 Columns with Highest Missing Values')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìà Numeric Features Analysis\n",
    "\n",
    "# %%\n",
    "# Get numeric columns\n",
    "numeric_cols = app_train.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "# Remove target and ID columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['TARGET', 'SK_ID_CURR']]\n",
    "\n",
    "print(f\"Number of numeric columns: {len(numeric_cols)}\")\n",
    "print(f\"First 10 numeric columns: {numeric_cols[:10]}\")\n",
    "\n",
    "# %%\n",
    "# Summary statistics for numeric columns\n",
    "print(\"Summary statistics for numeric columns:\")\n",
    "print(app_train[numeric_cols].describe().transpose())\n",
    "\n",
    "# %%\n",
    "# Visualize distributions of key numeric features\n",
    "key_features = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY',\n",
    "    'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    if feature in app_train.columns:\n",
    "        # Remove outliers for better visualization\n",
    "        data = app_train[feature].dropna()\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        filtered_data = data[(data >= Q1 - 1.5 * IQR) & (data <= Q3 + 1.5 * IQR)]\n",
    "        \n",
    "        axes[i].hist(filtered_data, bins=50, alpha=0.7, color='skyblue')\n",
    "        axes[i].set_title(f'Distribution of {feature}')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä Categorical Features Analysis\n",
    "\n",
    "# %%\n",
    "# Get categorical columns\n",
    "categorical_cols = app_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Number of categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# %%\n",
    "# Analyze key categorical features\n",
    "key_categorical = [\n",
    "    'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR',\n",
    "    'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "    'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE'\n",
    "]\n",
    "\n",
    "# Filter to columns that exist\n",
    "key_categorical = [col for col in key_categorical if col in app_train.columns]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(key_categorical):\n",
    "    if i < len(axes):\n",
    "        value_counts = app_train[feature].value_counts()\n",
    "        \n",
    "        # For features with many categories, show top 10\n",
    "        if len(value_counts) > 10:\n",
    "            top_values = value_counts.head(10)\n",
    "            axes[i].barh(range(len(top_values)), top_values.values)\n",
    "            axes[i].set_yticks(range(len(top_values)))\n",
    "            axes[i].set_yticklabels(top_values.index)\n",
    "        else:\n",
    "            axes[i].bar(range(len(value_counts)), value_counts.values)\n",
    "            axes[i].set_xticks(range(len(value_counts)))\n",
    "            axes[i].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
    "        \n",
    "        axes[i].set_title(f'{feature} Distribution')\n",
    "        axes[i].set_xlabel('Count')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üîó Relationships with Target\n",
    "\n",
    "# %%\n",
    "# Analyze how key features relate to target\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Credit amount by target\n",
    "if 'AMT_CREDIT' in app_train.columns:\n",
    "    axes[0, 0].boxplot([\n",
    "        app_train[app_train['TARGET'] == 0]['AMT_CREDIT'].dropna(),\n",
    "        app_train[app_train['TARGET'] == 1]['AMT_CREDIT'].dropna()\n",
    "    ], labels=['No Default', 'Default'])\n",
    "    axes[0, 0].set_title('Credit Amount by Target')\n",
    "    axes[0, 0].set_ylabel('Credit Amount')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Income by target\n",
    "if 'AMT_INCOME_TOTAL' in app_train.columns:\n",
    "    # Use log scale for better visualization\n",
    "    data_0 = np.log1p(app_train[app_train['TARGET'] == 0]['AMT_INCOME_TOTAL'].dropna())\n",
    "    data_1 = np.log1p(app_train[app_train['TARGET'] == 1]['AMT_INCOME_TOTAL'].dropna())\n",
    "    \n",
    "    axes[0, 1].boxplot([data_0, data_1], labels=['No Default', 'Default'])\n",
    "    axes[0, 1].set_title('Income (log scale) by Target')\n",
    "    axes[0, 1].set_ylabel('Log(Income + 1)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Age by target\n",
    "if 'DAYS_BIRTH' in app_train.columns:\n",
    "    # Convert to years\n",
    "    app_train['AGE'] = -app_train['DAYS_BIRTH'] / 365.25\n",
    "    axes[0, 2].boxplot([\n",
    "        app_train[app_train['TARGET'] == 0]['AGE'],\n",
    "        app_train[app_train['TARGET'] == 1]['AGE']\n",
    "    ], labels=['No Default', 'Default'])\n",
    "    axes[0, 2].set_title('Age by Target')\n",
    "    axes[0, 2].set_ylabel('Age (Years)')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Contract type by target\n",
    "if 'NAME_CONTRACT_TYPE' in app_train.columns:\n",
    "    contract_target = pd.crosstab(app_train['NAME_CONTRACT_TYPE'], app_train['TARGET'], normalize='index')\n",
    "    contract_target.plot(kind='bar', stacked=True, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Contract Type by Target')\n",
    "    axes[1, 0].set_ylabel('Percentage')\n",
    "    axes[1, 0].legend(['No Default', 'Default'])\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Gender by target\n",
    "if 'CODE_GENDER' in app_train.columns:\n",
    "    gender_target = pd.crosstab(app_train['CODE_GENDER'], app_train['TARGET'], normalize='index')\n",
    "    gender_target.plot(kind='bar', stacked=True, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Gender by Target')\n",
    "    axes[1, 1].set_ylabel('Percentage')\n",
    "    axes[1, 1].legend(['No Default', 'Default'])\n",
    "\n",
    "# 6. Education by target\n",
    "if 'NAME_EDUCATION_TYPE' in app_train.columns:\n",
    "    edu_target = pd.crosstab(app_train['NAME_EDUCATION_TYPE'], app_train['TARGET'], normalize='index')\n",
    "    edu_target = edu_target.sort_values(by=1, ascending=False)  # Sort by default rate\n",
    "    edu_target.plot(kind='bar', stacked=True, ax=axes[1, 2])\n",
    "    axes[1, 2].set_title('Education Type by Target')\n",
    "    axes[1, 2].set_ylabel('Percentage')\n",
    "    axes[1, 2].legend(['No Default', 'Default'])\n",
    "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä Correlation Analysis\n",
    "\n",
    "# %%\n",
    "# Calculate correlation matrix for key numeric features\n",
    "key_numeric = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY',\n",
    "    'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "    'REGION_POPULATION_RELATIVE', 'DAYS_REGISTRATION',\n",
    "    'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'CNT_FAM_MEMBERS',\n",
    "    'CNT_CHILDREN', 'TARGET'\n",
    "]\n",
    "\n",
    "# Filter to columns that exist\n",
    "key_numeric = [col for col in key_numeric if col in app_train.columns]\n",
    "\n",
    "if len(key_numeric) > 1:\n",
    "    corr_matrix = app_train[key_numeric].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=0.5)\n",
    "    plt.title('Correlation Matrix of Key Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show features most correlated with target\n",
    "    if 'TARGET' in corr_matrix.columns:\n",
    "        target_corr = corr_matrix['TARGET'].sort_values(ascending=False)\n",
    "        print(\"Features most correlated with TARGET:\")\n",
    "        print(target_corr.head(10))\n",
    "        print(\"\\nFeatures least correlated with TARGET:\")\n",
    "        print(target_corr.tail(10))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìÅ Explore Other Data Files\n",
    "\n",
    "# %%\n",
    "# Load bureau data (sample)\n",
    "print(\"Loading bureau data (5% sample)...\")\n",
    "bureau = load_data(config['files']['bureau'], nrows=50000)  # Adjust nrows as needed\n",
    "print(f\"Bureau data shape: {bureau.shape}\")\n",
    "\n",
    "# %%\n",
    "# Display bureau data information\n",
    "if bureau is not None:\n",
    "    display_data_info(bureau, \"Bureau Data\")\n",
    "    \n",
    "    # Show relationship with main application\n",
    "    print(f\"\\nUnique clients in bureau: {bureau['SK_ID_CURR'].nunique()}\")\n",
    "    print(f\"Unique loans in bureau: {bureau['SK_ID_BUREAU'].nunique()}\")\n",
    "    \n",
    "    # Show credit types distribution\n",
    "    if 'CREDIT_TYPE' in bureau.columns:\n",
    "        print(\"\\nCredit Types in Bureau:\")\n",
    "        print(bureau['CREDIT_TYPE'].value_counts().head(10))\n",
    "\n",
    "# %%\n",
    "# Load previous application data (sample)\n",
    "print(\"\\nLoading previous application data (5% sample)...\")\n",
    "prev_app = load_data(config['files']['previous_application'], nrows=50000)\n",
    "print(f\"Previous application data shape: {prev_app.shape}\")\n",
    "\n",
    "# %%\n",
    "# Display previous application information\n",
    "if prev_app is not None:\n",
    "    display_data_info(prev_app, \"Previous Application Data\")\n",
    "    \n",
    "    # Show application status\n",
    "    if 'NAME_CONTRACT_STATUS' in prev_app.columns:\n",
    "        print(\"\\nPrevious Application Status:\")\n",
    "        status_counts = prev_app['NAME_CONTRACT_STATUS'].value_counts()\n",
    "        print(status_counts)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        status_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Previous Application Status Distribution')\n",
    "        plt.ylabel('')\n",
    "        plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìù Key Insights\n",
    "\n",
    "# %%\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY INSIGHTS FROM DATA EXPLORATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. TARGET DISTRIBUTION:\")\n",
    "print(f\"   - Only {target_pct[1]:.2f}% of clients have payment difficulties\")\n",
    "print(f\"   - This is a highly imbalanced classification problem\")\n",
    "\n",
    "print(\"\\n2. DATA QUALITY:\")\n",
    "print(f\"   - Training data has {app_train.shape[0]:,} rows and {app_train.shape[1]} columns\")\n",
    "print(f\"   - {len(missing_df)} columns have missing values\")\n",
    "print(f\"   - Overall missing data: {100 * missing.sum() / (app_train.shape[0] * app_train.shape[1]):.2f}%\")\n",
    "\n",
    "print(\"\\n3. KEY PATTERNS:\")\n",
    "print(\"   - Default rate varies by demographic factors:\")\n",
    "if 'CODE_GENDER' in app_train.columns:\n",
    "    gender_default = app_train.groupby('CODE_GENDER')['TARGET'].mean() * 100\n",
    "    for gender, rate in gender_default.items():\n",
    "        print(f\"     * {gender}: {rate:.2f}% default rate\")\n",
    "\n",
    "if 'NAME_EDUCATION_TYPE' in app_train.columns:\n",
    "    edu_default = app_train.groupby('NAME_EDUCATION_TYPE')['TARGET'].mean() * 100\n",
    "    print(f\"   - Education impact: Lower education = higher default risk\")\n",
    "\n",
    "print(\"\\n4. NEXT STEPS:\")\n",
    "print(\"   - Need to handle imbalanced data (oversampling/undersampling)\")\n",
    "print(\"   - Need to handle missing values\")\n",
    "print(\"   - Need feature engineering from multiple data sources\")\n",
    "print(\"   - Consider ensemble methods for better performance\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üíæ Save Exploration Results\n",
    "\n",
    "# %%\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'target_distribution': dict(target_pct) if 'TARGET' in app_train.columns else {},\n",
    "    'data_shape': app_train.shape,\n",
    "    'missing_values': missing.sum(),\n",
    "    'missing_percentage': 100 * missing.sum() / (app_train.shape[0] * app_train.shape[1]),\n",
    "    'numeric_features': len(numeric_cols),\n",
    "    'categorical_features': len(categorical_cols)\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "import json\n",
    "with open('exploration_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=4)\n",
    "\n",
    "print(\"Exploration summary saved to exploration_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".credit_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
